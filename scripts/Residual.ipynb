{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Nucleus-segmentation/env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, add, BatchNormalization, Activation, Lambda\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Layer\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.metrics import categorical_accuracy\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# from .base_network import BaseNetwork\n",
    "# from .custom_layers.SpatialTransformLayer import SpatialTransformLayer\n",
    "\n",
    "# from skimage.transform import resize\n",
    "# from skimage.io import imread\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# class MicroblinkBaseNet(BaseNetwork):\n",
    "#     def __init__(self, output_directory, checkpoint_directory, config_dict, preprocessor, name = \"MicroblinkBaseNet\", train = True):\n",
    "#         BaseNetwork.__init__(self, output_directory, checkpoint_directory, config_dict, preprocessor, name=name, train = train)\n",
    "#         y, x = config_dict['STNOutputSize'].split(',')\n",
    "#         x = int(x)\n",
    "#         y = int(y)\n",
    "#         self.STN_output_size = (y, x)\n",
    "#         self.train_localization = bool(config_dict['TrainLocalization'])\n",
    "\n",
    "    \n",
    "# #     def get_localization_network(self, inputs):\n",
    "# #         # initial weights for localization network for identity transform\n",
    "# #         b = np.zeros((2, 3), dtype='float32')\n",
    "# #         b[0, 0] = 1\n",
    "# #         b[1, 1] = 1 \n",
    "# #         W = np.zeros((50, 6), dtype='float32')\n",
    "# #         weights = [W, b.flatten()]\n",
    "\n",
    "\n",
    "# #         # initial weights for localization network zoom on top of image\n",
    "# #         # b = np.zeros((2, 3), dtype='float32')\n",
    "# #         # b[0, 0] = 1\n",
    "# #         # b[1, 1] = 0.3\n",
    "# #         # b[1, 2] = -0.7\n",
    "# #         # W = np.zeros((50, 6), dtype='float32')\n",
    "# #         # weights = [W, b.flatten()]\n",
    "\n",
    "# #         # s = Lambda(lambda x: x / 255.) (inputs)\n",
    "\n",
    "# #         locnet = Convolution2D(16, (11, 11), activation='relu', name = 'localization_conv_1')(inputs)\n",
    "# #         locnet = Convolution2D(16, (1, 11), activation='relu', name = 'localization_conv_2')(inputs)\n",
    "# #         locnet = MaxPooling2D(pool_size=(2,2), name = 'localization_maxpool_1')(locnet)\n",
    "\n",
    "# #         locnet = Convolution2D(32, (7, 7), activation='relu', name = 'localization_conv_3')(locnet)\n",
    "# #         locnet = Convolution2D(32, (7, 7), activation='relu', name = 'localization_conv_4')(locnet)\n",
    "# #         locnet = MaxPooling2D(pool_size=(2,2), name = 'localization_maxpool_2')(locnet)\n",
    "\n",
    "# #         locnet = Convolution2D(64, (5, 5), activation='relu', name = 'localization__conv_5')(locnet)\n",
    "# #         locnet = Convolution2D(64, (5, 5), activation='relu', name = 'localization_conv_6')(locnet)\n",
    "# #         locnet = MaxPooling2D(pool_size=(2,2), name = 'localization_maxpool_3')(locnet)\n",
    "\n",
    "# #         locnet = Convolution2D(32, (3, 3), activation='relu', name = 'localization_conv_7')(locnet)\n",
    "# #         locnet = Convolution2D(32, (3, 3), activation='relu', name = 'localization_conv_8')(locnet)\n",
    "# #         locnet = MaxPooling2D(pool_size=(2,2), name = 'localization_maxpool_4')(locnet)\n",
    "\n",
    "# #         locnet = Convolution2D(16, (3, 3), activation='relu', name = 'localization_conv_9')(locnet)\n",
    "# #         locnet = Convolution2D(16, (3, 3), activation='relu', name = 'localization_conv_10')(locnet)\n",
    "# #         locnet = MaxPooling2D(pool_size=(2,2), name = 'localization_maxpool_5')(locnet)\n",
    "\n",
    "# #         locnet = Flatten()(locnet)\n",
    "# #         locnet = Dense(50, activation = 'relu', name = 'localization_dense_1')(locnet)\n",
    "# #         locnet = Dense(6, weights=weights, name = 'localization_dense_affine')(locnet)\n",
    "# #         locnet = Model(inputs = [inputs], outputs = [locnet])\n",
    "\n",
    "# #         return locnet\n",
    "\n",
    "\n",
    "#     def get_network(self):\n",
    "\n",
    "#         inputs = Input(self.preprocessor.get_shape())\n",
    "\n",
    "# #         self.locnet = self.get_localization_network(inputs)\n",
    "        \n",
    "# #         for layer in self.locnet.layers:\n",
    "# #             layer.trainable = self.train_localization\n",
    "\n",
    "# #         outputs = SpatialTransformLayer(localization_net=self.locnet,\n",
    "# #                                      output_size=self.STN_output_size, name='spatial_layer_1')(inputs)\n",
    "\n",
    "\n",
    "#         # s = Lambda(lambda x: x / 255.) (outputs)\n",
    "\n",
    "#         outputs = Convolution2D(32, (3, 3), padding='same', activation = 'relu', name = 'classification_conv_1')(outputs)\n",
    "#         outputs = MaxPooling2D(pool_size=(2,2), name = 'classification_maxpool_1')(outputs)\n",
    "\n",
    "#         outputs = Convolution2D(32, (3, 3), padding='same', activation = 'relu', name = 'classification_conv_2')(outputs)\n",
    "#         outputs = MaxPooling2D(pool_size=(2,2), name = 'classification_maxpool_2')(outputs)\n",
    "\n",
    "#         outputs = Convolution2D(32, (3, 3), padding='same', activation = 'relu', name = 'classification_conv_3')(outputs)\n",
    "#         outputs = MaxPooling2D(pool_size=(2,2), name = 'classification_maxpool_3')(outputs)\n",
    "\n",
    "#         outputs = Convolution2D(32, (3, 3), padding='same', activation = 'relu', name = 'classification_conv_4')(outputs)\n",
    "#         outputs = MaxPooling2D(pool_size=(2,2), name = 'classification_maxpool_4')(outputs)\n",
    "\n",
    "#         outputs = Convolution2D(32, (3, 3), padding='same', activation = 'relu', name = 'classification_conv_5')(outputs)\n",
    "#         outputs = MaxPooling2D(pool_size=(2,2), name = 'classification_maxpool_5')(outputs)\n",
    "\n",
    "#         outputs = Convolution2D(32, (3, 3), padding='same', activation = 'relu', name = 'classification_conv_6')(outputs)\n",
    "#         outputs = MaxPooling2D(pool_size=(2,2), name = 'classification_maxpool_6')(outputs)\n",
    "\n",
    "#         outputs = Flatten()(outputs)\n",
    "#         outputs = Dense(256, activation = 'relu', name = 'classification_dense_1')(outputs)\n",
    "#         outputs = Dense(self.number_of_classes, activation='softmax', name = 'classification_dense_probs')(outputs)\n",
    "\n",
    "#         model = Model(inputs=[inputs], outputs=[outputs])\n",
    "#         model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "#         model.summary()\n",
    "\n",
    "#         X_in = model.input\n",
    "#         X_transformed = model.layers[1].output\n",
    "#         print(model.layers[1].name)\n",
    "#         self.transformation_operation = K.function([X_in], [X_transformed])\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def get_additional_callbacks(self):\n",
    "#         return []#[OutputsCallback(self.transformation_operation, self.preprocessor.X_train, self.preprocessor.IMG_HEIGHT, self.preprocessor.IMG_WIDTH, self.preprocessor.IMG_CHANNELS)] #return array of new callbacks [EarlyStopping(..), ..]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual block mapping 64 channels to 128 channels built\n",
      "Residual block mapping 128 channels to 128 channels built\n",
      "Residual block mapping 128 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Residual block mapping 256 channels to 256 channels built\n",
      "Tensor(\"add_205/add:0\", shape=(?, 112, 112, 256), dtype=float32)\n",
      "Tensor(\"conv2d_497/Sigmoid:0\", shape=(?, 112, 112, 1), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 112, 112, 64) 3200        input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 112, 112, 64) 256         conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 112, 112, 64) 0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 112, 112, 128 73856       activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 112, 112, 128 512         conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 112, 112, 128 0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 112, 112, 128 8320        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 112, 112, 128 147584      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_193 (Add)                   (None, 112, 112, 128 0           conv2d_469[0][0]                 \n",
      "                                                                 conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 112, 112, 128 512         add_193[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 112, 112, 128 0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 112, 112, 128 147584      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 112, 112, 128 512         conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 112, 112, 128 0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 112, 112, 128 147584      activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_194 (Add)                   (None, 112, 112, 128 0           add_193[0][0]                    \n",
      "                                                                 conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 112, 112, 128 512         add_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 112, 112, 128 0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 112, 112, 256 295168      activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 112, 112, 256 1024        conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 112, 112, 256 0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 112, 112, 256 33024       add_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 112, 112, 256 590080      activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_195 (Add)                   (None, 112, 112, 256 0           conv2d_474[0][0]                 \n",
      "                                                                 conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 112, 112, 256 1024        add_195[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 112, 112, 256 0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 112, 112, 256 590080      activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 112, 112, 256 1024        conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 112, 112, 256 0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 112, 112, 256 590080      activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_196 (Add)                   (None, 112, 112, 256 0           add_195[0][0]                    \n",
      "                                                                 conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 56, 56, 256)  0           add_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 56, 56, 256)  1024        max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 56, 56, 256)  0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 56, 56, 256)  590080      activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 56, 56, 256)  1024        conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 56, 56, 256)  0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 56, 56, 256)  590080      activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_199 (Add)                   (None, 56, 56, 256)  0           max_pooling2d_31[0][0]           \n",
      "                                                                 conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D) (None, 28, 28, 256)  0           add_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 28, 28, 256)  1024        max_pooling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 28, 28, 256)  0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 28, 28, 256)  590080      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 28, 28, 256)  1024        conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 28, 28, 256)  0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 28, 28, 256)  590080      activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_201 (Add)                   (None, 28, 28, 256)  0           max_pooling2d_32[0][0]           \n",
      "                                                                 conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 28, 28, 256)  1024        add_201[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 28, 28, 256)  0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 56, 56, 256)  1024        add_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 28, 28, 256)  590080      activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 56, 56, 256)  0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 28, 28, 256)  1024        conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 56, 56, 256)  590080      activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 28, 28, 256)  0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 56, 56, 256)  1024        conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 28, 28, 256)  590080      activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 56, 56, 256)  0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 112, 112, 256 1024        add_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_202 (Add)                   (None, 28, 28, 256)  0           add_201[0][0]                    \n",
      "                                                                 conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 56, 56, 256)  590080      activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 112, 112, 256 0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_31 (UpSampling2D) (None, 56, 56, 256)  0           add_202[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_200 (Add)                   (None, 56, 56, 256)  0           add_199[0][0]                    \n",
      "                                                                 conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 112, 112, 256 590080      activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_203 (Add)                   (None, 56, 56, 256)  0           up_sampling2d_31[0][0]           \n",
      "                                                                 add_200[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 112, 112, 256 1024        conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 56, 56, 256)  1024        add_203[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 112, 112, 256 0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 56, 56, 256)  0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 112, 112, 256 590080      activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 56, 56, 256)  590080      activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_197 (Add)                   (None, 112, 112, 256 0           add_196[0][0]                    \n",
      "                                                                 conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 56, 56, 256)  1024        conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 112, 112, 256 1024        add_197[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 56, 56, 256)  0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 112, 112, 256 0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 56, 56, 256)  590080      activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 112, 112, 256 590080      activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_204 (Add)                   (None, 56, 56, 256)  0           add_203[0][0]                    \n",
      "                                                                 conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 112, 112, 256 1024        conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_32 (UpSampling2D) (None, 112, 112, 256 0           add_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 112, 112, 256 0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 112, 112, 256 65792       up_sampling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 112, 112, 256 590080      activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 112, 112, 256 65792       conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_198 (Add)                   (None, 112, 112, 256 0           add_197[0][0]                    \n",
      "                                                                 conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 112, 112, 256 0           conv2d_494[0][0]                 \n",
      "                                                                 add_198[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 112, 112, 256 1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 112, 112, 256 0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 112, 112, 256 590080      activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 112, 112, 256 1024        conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 112, 112, 256 0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 112, 112, 256 590080      activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_205 (Add)                   (None, 112, 112, 256 0           lambda_1[0][0]                   \n",
      "                                                                 conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 112, 112, 1)  257         add_205[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,221,441\n",
      "Trainable params: 12,210,561\n",
      "Non-trainable params: 10,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def conv_block(feat_maps_out, prev):\n",
    "    prev = BatchNormalization()(prev) # Specifying the axis and mode allows for later merging\n",
    "    prev = Activation('relu')(prev)\n",
    "    prev = Conv2D(feat_maps_out, (3, 3), padding='same')(prev) \n",
    "    prev = BatchNormalization()(prev) # Specifying the axis and mode allows for later merging\n",
    "    prev = Activation('relu')(prev)\n",
    "    prev = Conv2D(feat_maps_out, (3, 3), padding='same')(prev) \n",
    "    return prev\n",
    "\n",
    "\n",
    "def skip_block(feat_maps_in, feat_maps_out, prev):\n",
    "    if feat_maps_in != feat_maps_out:\n",
    "        # This adds in a 1x1 convolution on shortcuts that map between an uneven amount of channels\n",
    "        prev = Conv2D(feat_maps_out, (1, 1), padding='same')(prev)\n",
    "    return prev \n",
    "\n",
    "\n",
    "def Residual(feat_maps_in, feat_maps_out, prev_layer):\n",
    "    '''\n",
    "    A customizable residual unit with convolutional and shortcut blocks\n",
    "    Args:\n",
    "      feat_maps_in: number of channels/filters coming in, from input or previous layer\n",
    "      feat_maps_out: how many output channels/filters this block will produce\n",
    "      prev_layer: the previous layer\n",
    "    '''\n",
    "\n",
    "    skip = skip_block(feat_maps_in, feat_maps_out, prev_layer)\n",
    "    conv = conv_block(feat_maps_out, prev_layer)\n",
    "\n",
    "    return add([skip, conv]) # the residual connection\n",
    "\n",
    "def ResidualAttention(inputs, p = 1, t = 2, r = 1):\n",
    "    channel_axis = -1\n",
    "    num_channels = inputs._keras_shape[channel_axis]\n",
    "    \n",
    "    first_residuals = inputs\n",
    "    for i in range(p):\n",
    "        first_residuals = Residual(num_channels, num_channels, first_residuals)\n",
    "        \n",
    "    output_trunk = first_residuals    \n",
    "    for i in range(t):\n",
    "        output_trunk = Residual(num_channels, num_channels, output_trunk)\n",
    "        \n",
    "    output_soft_mask = MaxPooling2D(pool_size=(2,2))(first_residuals)    \n",
    "    for i in range(r):\n",
    "        output_soft_mask = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    \n",
    "    #skip connection\n",
    "    output_skip_connection = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    \n",
    "    #2r residual blocks and first upsampling\n",
    "    output_soft_mask = MaxPooling2D(pool_size=(2,2))(output_soft_mask)    \n",
    "    for i in range(2*r):\n",
    "        output_soft_mask = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    output_soft_mask = UpSampling2D([2, 2])(output_soft_mask)\n",
    "    \n",
    "    #addition of the skip connection\n",
    "    output_soft_mask = add([output_soft_mask, output_skip_connection])         \n",
    "    \n",
    "    #last r blocks of residuals and upsampling\n",
    "    for i in range(r):\n",
    "        output_soft_mask = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    output_soft_mask = UpSampling2D([2, 2])(output_soft_mask)\n",
    "    \n",
    "    #final attention output\n",
    "    output_soft_mask = Conv2D(num_channels, (1,1), activation='relu')(output_soft_mask)\n",
    "    #final attention output\n",
    "    output_soft_mask = Conv2D(num_channels, (1,1), activation='sigmoid')(output_soft_mask)\n",
    "    \n",
    "    output = Lambda(lambda x:(1 + x[0]) * x[1])([output_soft_mask,output_trunk])\n",
    "    for i in range(p):\n",
    "        output = Residual(num_channels, num_channels, output)\n",
    "        \n",
    "    return output\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "img_rows = 224  \n",
    "img_cols = 224\n",
    "\n",
    "inp = Input((img_rows, img_cols, 1))\n",
    "cnv1 = Conv2D(64, (7, 7), strides=[2,2], activation='relu', padding='same')(inp)\n",
    "r1 = Residual(64, 128, cnv1)\n",
    "# An example residual unit coming after a convolutional layer. NOTE: the above residual takes the 64 output channels\n",
    "# from the Convolutional2D layer as the first argument to the Residual function\n",
    "r2 = Residual(128, 128, r1)\n",
    "r3 = Residual(128, 256, r2)\n",
    "r3 = ResidualAttention(r3)\n",
    "out = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(r3)\n",
    "print(out)\n",
    "\n",
    "model = Model(inputs = [inp], outputs = [out])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nucleus-segmentation",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
