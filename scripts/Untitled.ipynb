{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor input path ../inputs/mozgalo\n",
      "{'TestPercentage': '0.3', 'ImgWidth': '600', 'ImgHeight': '1100', 'ImgChannels': '1', 'RotationRange': '20', 'PreprocessorModule': 'microblink_base_preprocessor_imgaug_center_loss', 'WidthShiftRange': '0.15', 'TopSideOnly': 'False', 'ShearRange': '0.2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Mozgalo/inputs/test/0.jpg\n",
      "[[6.0713492e-06 1.3280326e-06 1.4464332e-05 2.7363678e-06 7.7001721e-05\n",
      "  1.4037850e-04 1.7773373e-05 3.3414037e-06 2.5148873e-05 2.5548745e-06\n",
      "  5.4022826e-06 6.9140606e-06 4.8951108e-05 8.9695670e-05 6.0279035e-05\n",
      "  1.7128898e-06 1.1713188e-06 9.9922287e-01 1.6733919e-05 2.0749167e-06\n",
      "  1.0380076e-05 1.8639777e-04 4.6262317e-06 5.0355749e-05 1.5246035e-06]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import argparse\n",
    "import configparser\n",
    "from shutil import copyfile\n",
    "from importlib import import_module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import ImageFile #jedan je buggy malo\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "from skimage.io import imread\n",
    "\n",
    "import warnings\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.optionxform = str\n",
    "config.read(\"./config.cfg\")\n",
    "\n",
    "ModelName = \"\"\n",
    "PreprocessorName = \"MicroblinkBasePreprocessorImgaugCenterLoss\"\n",
    "\n",
    "# model_parameters = dict(config.items(args.ModelName))\n",
    "preprocessor_parameters = dict(config.items(PreprocessorName))\n",
    "data_parameters = dict(config.items('Data'))\n",
    "\n",
    "#load preprocessor\n",
    "module_name = preprocessor_parameters['PreprocessorModule']\n",
    "input_path = data_parameters['Inputs']\n",
    "\n",
    "module = import_module(\"preprocessors.%s\" % (module_name))\n",
    "preprocessor_class = getattr(module, PreprocessorName)\n",
    "preprocessor = preprocessor_class(input_path, preprocessor_parameters) #needs to be changed for processor params or something\n",
    "\n",
    "#load network model\n",
    "# module_name = model_parameters['ModelModule']\n",
    "checkpoint_dir = data_parameters['CheckpointDirectory']\n",
    "result_path = data_parameters['Outputs']\n",
    "\n",
    "# module = import_module(\"models.%s\" % (module_name))\n",
    "# ml_class= getattr(module, args.ModelName)\n",
    "# my_model = ml_class(result_path, checkpoint_dir, model_parameters, preprocessor, train=False)\n",
    "# my_model.init_network()\n",
    "\n",
    "\n",
    "# my_model.model.load_weights('/home/user/Mozgalo/checkpoints/ResidualAttentionInceptionReductionNetSmallDifferentInterpolationCenterLoss/MicroblinkBasePreprocessorImgaugCenterLoss/2018-04-24__12_01_45BatchNorm/0.0259-0023.hdf5', by_name = True, skip_mismatch = True)\n",
    "my_model = get_network()\n",
    "rename_layers(my_model, 'first')\n",
    "my_model.load_weights('/home/user/Mozgalo/final_model/models/first_model.hdf5')\n",
    "\n",
    "root = '../inputs/test'\n",
    "root = os.path.abspath(root)\n",
    "warnings.simplefilter('ignore', DeprecationWarning) #zbog sklearna i numpy deprecationa u label encoderu\n",
    "key = lambda x: int(x.split('/')[-1].split('.')[0])\n",
    "\n",
    "threshold = 0.95 # 0.95 resnet s center lossom dao 0.901\n",
    "results = []\n",
    "confidence = []\n",
    "original_results = []\n",
    "cnt_others = 0\n",
    "for file_name in tqdm(sorted(os.listdir(root), key = key)):\n",
    "    full_path = os.path.join(root, file_name)\n",
    "    print(full_path)\n",
    "    image = preprocessor.process_data(full_path)\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    # result = my_model.model.predict(image)[0]\n",
    "    result = my_model.predict([image])\n",
    "    print(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, add, BatchNormalization, Activation, Lambda, GlobalAveragePooling2D, GlobalMaxPooling2D, Embedding\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Layer\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.metrics import categorical_accuracy\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def conv_block(feat_maps_out, prev):\n",
    "    prev = BatchNormalization()(prev) # Specifying the axis and mode allows for later merging\n",
    "    prev = Activation('relu')(prev)\n",
    "    prev = Conv2D(feat_maps_out, (3, 3), padding='same')(prev) \n",
    "    prev = BatchNormalization()(prev) # Specifying the axis and mode allows for later merging\n",
    "    prev = Activation('relu')(prev)\n",
    "    prev = Conv2D(feat_maps_out, (3, 3), padding='same')(prev) \n",
    "    return prev\n",
    "\n",
    "\n",
    "def skip_block(feat_maps_in, feat_maps_out, prev):\n",
    "    if feat_maps_in != feat_maps_out:\n",
    "        # This adds in a 1x1 convolution on shortcuts that map between an uneven amount of channels\n",
    "        prev = Conv2D(feat_maps_out, (1, 1), padding='same')(prev)\n",
    "    return prev \n",
    "\n",
    "\n",
    "def Residual(feat_maps_in, feat_maps_out, prev_layer):\n",
    "    '''\n",
    "    A customizable residual unit with convolutional and shortcut blocks\n",
    "    Args:\n",
    "      feat_maps_in: number of channels/filters coming in, from input or previous layer\n",
    "      feat_maps_out: how many output channels/filters this block will produce\n",
    "      prev_layer: the previous layer\n",
    "    '''\n",
    "\n",
    "    skip = skip_block(feat_maps_in, feat_maps_out, prev_layer)\n",
    "    conv = conv_block(feat_maps_out, prev_layer)\n",
    "    return add([skip, conv]) # the residual connection\n",
    "\n",
    "def ResidualAttention(inputs, p = 1, t = 2, r = 1):\n",
    "    channel_axis = -1\n",
    "    num_channels = inputs._keras_shape[channel_axis]\n",
    "    \n",
    "    first_residuals = inputs\n",
    "    for i in range(p):\n",
    "        first_residuals = Residual(num_channels, num_channels, first_residuals)\n",
    "        \n",
    "    output_trunk = first_residuals    \n",
    "    for i in range(t):\n",
    "        output_trunk = Residual(num_channels, num_channels, output_trunk)\n",
    "        \n",
    "\n",
    "    size1 = first_residuals._keras_shape[1:3]\n",
    "    output_soft_mask = MaxPooling2D(pool_size=(2,2), padding='same')(first_residuals) \n",
    "    for i in range(r):\n",
    "        output_soft_mask = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    \n",
    "    #skip connection\n",
    "    output_skip_connection = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    \n",
    "    #2r residual blocks and first upsampling \n",
    "    size2 = output_soft_mask._keras_shape[1:3]\n",
    "    output_soft_mask = MaxPooling2D(pool_size=(2,2), padding='same')(output_soft_mask) \n",
    "    for i in range(2*r):\n",
    "        output_soft_mask = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    # output_soft_mask = UpSampling2D([2, 2])(output_soft_mask)\n",
    "    output_soft_mask = Lambda(lambda x: tf.image.resize_images(x,\n",
    "                                                size2,\n",
    "                                                method=tf.image.ResizeMethod.BILINEAR,\n",
    "                                                align_corners=False\n",
    "                                            ))(output_soft_mask)\n",
    "\n",
    "\n",
    "\n",
    "    #addition of the skip connection\n",
    "    output_soft_mask = add([output_soft_mask, output_skip_connection])    \n",
    "    #last r blocks of residuals and upsampling\n",
    "    for i in range(r):\n",
    "        output_soft_mask = Residual(num_channels, num_channels, output_soft_mask)\n",
    "    # output_soft_mask = UpSampling2D([2, 2])(output_soft_mask)\n",
    "    output_soft_mask = Lambda(lambda x: tf.image.resize_images(x,\n",
    "                                                size1,\n",
    "                                                method=tf.image.ResizeMethod.BILINEAR,\n",
    "                                                align_corners=False\n",
    "                                            ))(output_soft_mask)\n",
    "    \n",
    "    #final attention output\n",
    "    output_soft_mask = Conv2D(num_channels, (1,1), activation='relu')(output_soft_mask)\n",
    "    #final attention output\n",
    "    output_soft_mask = Conv2D(num_channels, (1,1), activation='sigmoid')(output_soft_mask)\n",
    "    \n",
    "    output = Lambda(lambda x:(1 + x[0]) * x[1])([output_soft_mask,output_trunk])\n",
    "    for i in range(p):\n",
    "        output = Residual(num_channels, num_channels, output)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def get_network():\n",
    "    p = 1\n",
    "    t = 2\n",
    "    r = 1\n",
    "    number_of_classes = 25\n",
    "    \n",
    "    inputs = Input((1100,600,1))\n",
    "    outputs = Lambda(lambda x: (x /255. -0.5) * 2)(inputs)\n",
    "\n",
    "    outputs = Conv2D(8, (7, 7), strides = [2,2], padding='same', activation = 'relu', name = 'classification_conv_1')(outputs)\n",
    "    outputs = MaxPooling2D(pool_size=(3,3), strides = [2,2], padding='SAME' , name = 'classification_maxpool_1')(outputs)\n",
    "\n",
    "    outputs = Residual(8, 16, outputs)\n",
    "    outputs = ResidualAttention(outputs, p = p, t = t, r = r)\n",
    "    outputs = MaxPooling2D(pool_size=(3,3), strides = [2,2], padding='SAME' , name = 'classification_maxpool_2')(outputs)\n",
    "    outputs = Residual(16, 32, outputs)\n",
    "    outputs = ResidualAttention(outputs, p = p, t = t, r = r)\n",
    "    outputs = MaxPooling2D(pool_size=(3,3), strides = [2,2], padding='SAME' , name = 'classification_maxpool_3')(outputs) \n",
    "    outputs = Residual(32, 64, outputs)\n",
    "    outputs = ResidualAttention(outputs, p = p, t = t, r = r)\n",
    "    outputs = MaxPooling2D(pool_size=(3,3), strides = [2,2], padding='SAME' , name = 'classification_maxpool_4')(outputs)\n",
    "    outputs = Residual(64, 128, outputs)\n",
    "\n",
    "    outputs = BatchNormalization()(outputs) \n",
    "    outputs = GlobalAveragePooling2D()(outputs)\n",
    "    # outputs = GlobalMaxPooling2D()(outputs)\n",
    "    outputs = Dense(256, name = 'classification_dense_1', activation='relu')(outputs)\n",
    "    center_loss_layer = outputs\n",
    "    outputs = Dense(number_of_classes, activation='softmax', name = 'class_prob')(center_loss_layer)\n",
    "\n",
    "    model = Model(inputs=[inputs],outputs=[outputs])        \n",
    "    model.compile(loss=[\"categorical_crossentropy\"], optimizer=Adam(0.0001), metrics=[categorical_accuracy])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rename_layers(model, sufix):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        name = layer.name.split('_')[:-1]\n",
    "        name = \"_\".join(name)\n",
    "        layer.name = name + \"_\" + sufix + \"_\" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nucleus-segmentation",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
